<img width="1768" height="716" alt="image" src="https://github.com/user-attachments/assets/a7241bea-dd53-466e-967f-1a97fbb3206e" />## üöÄ Como Executar as Quest√µes no Google Colab

O projeto est√° dividido em m√∫ltiplos notebooks, cada um correspondendo a uma quest√£o ou etapa da an√°lise. Todos foram preparados para rodar diretamente no Google Colab.

Abaixo voc√™ encontrar√° o mapeamento de cada notebook, os dados que ele utiliza e um link direto para abri-lo no Colab.

### Mapeamento de Quest√µes e Datasets

| Arquivo do Notebook | Dataset(s) Utilizado(s)             | Descri√ß√£o da Quest√£o                                       | Link Direto para o Colab                                                                                                                                                             |
| ------------------- | ----------------------------------- | ---------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Q5.ipynb** | `heart_desease_data.csv`     | <img width="1215" height="569" alt="image" src="https://github.com/user-attachments/assets/8becbb15-4e47-46b5-94e7-4c3cbb54714c" /> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Eduardo-Mati/Projetos-integrador---Desafio-unifacisa---Modelos-de-Machine-Learning/blob/main/Q5.ipynb) |
| **Q6.ipynb** | `California Housing do Scikit-Learn, j√° presente importado no c√≥digo`     | <img width="1199" height="493" alt="image" src="https://github.com/user-attachments/assets/937f351c-7431-4eeb-a88c-257fcd63565e" /> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Eduardo-Mati/Projetos-integrador---Desafio-unifacisa---Modelos-de-Machine-Learning/blob/main/Q6.ipynb) |
| **Q7.ipynb** | `Groceries_dataset.csv`     | <img width="1161" height="465" alt="image" src="https://github.com/user-attachments/assets/aef20693-4f65-4ac9-a84f-50c8b47fb633" /> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Eduardo-Mati/Projetos-integrador---Desafio-unifacisa---Modelos-de-Machine-Learning/blob/main/Q7.ipynb) |
| **Q8.ipynb** | `avaliacoes_filmes.csv`     | <img width="1178" height="517" alt="image" src="https://github.com/user-attachments/assets/eb281138-b7ef-4da9-b1fb-cc78a44664ef" /> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Eduardo-Mati/Projetos-integrador---Desafio-unifacisa---Modelos-de-Machine-Learning/blob/main/Q8.ipynb) |
| **Q9.ipynb** | `paultimothymooney/chest-xray-pneumonia j√° importado dentro do c√≥digo`     | <img width="1191" height="535" alt="image" src="https://github.com/user-attachments/assets/b80529ba-60eb-43c4-938a-4a1227973309" /> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Eduardo-Mati/Projetos-integrador---Desafio-unifacisa---Modelos-de-Machine-Learning/blob/main/Q9.ipynb) |
| **Q10.ipynb** | `store.csv`  | <img width="918" height="732" alt="image" src="https://github.com/user-attachments/assets/4fcbfef3-8f04-4310-81e0-13e36c55c976" /> | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Eduardo-Mati/Projetos-integrador---Desafio-unifacisa---Modelos-de-Machine-Learning/blob/main/Q10.ipynb) |


### Instru√ß√µes de Execu√ß√£o

1.  **Escolha a Quest√£o:** Na tabela acima, clique no bot√£o "Open In Colab" correspondente √† quest√£o que voc√™ deseja executar.
2.  **Execute a C√©lula de Configura√ß√£o:** Como antes, a **primeira c√©lula** de cada notebook deve ser executada primeiro para clonar o reposit√≥rio e instalar as bibliotecas. Isso garante que o notebook ter√° acesso aos arquivos de dataset corretos.
3.  **Execute o Restante do C√≥digo:** Ap√≥s a configura√ß√£o, execute as outras c√©lulas em sequ√™ncia para ver a an√°lise completa daquela quest√£o.

### Funcionamento do c√≥digo por etapa


Quest√£o 5 (Intermedi√°rio) - Diagn√≥stico de Doen√ßas Card√≠aca


<img width="585" height="851" alt="image" src="https://github.com/user-attachments/assets/0a36d36a-3398-4010-bd09-8d8f25f8310c" />

 
1. Importa√ß√£o das Bibliotecas
O c√≥digo √© organizado em se√ß√µes para importar diferentes tipos de ferramentas:

‚Ä¢	Manipula√ß√£o de Dados:

o	import pandas as pd: A biblioteca principal para carregar e manipular os dados em tabelas (DataFrames).

o	import numpy as np: Usada para opera√ß√µes matem√°ticas e num√©ricas.

‚Ä¢	Visualiza√ß√£o:

o	import matplotlib.pyplot as plt e import seaborn as sns: Duas bibliotecas usadas para criar gr√°ficos e visualizar os dados.

‚Ä¢	Pr√©-processamento:

o	from sklearn.model_selection import train_test_split: Fun√ß√£o essencial para dividir os dados em conjuntos de treino e teste.

o	from sklearn.preprocessing import ...: Importa ferramentas para "limpar" os dados antes de us√°-los:

ÔÇß	StandardScaler, MinMaxScaler: Para normalizar ou padronizar as colunas num√©ricas (coloc√°-las na mesma escala).

ÔÇß	OneHotEncoder: Para converter colunas de texto (categ√≥ricas) em n√∫meros que o modelo possa entender.

o	from sklearn.impute import SimpleImputer: Ferramenta para preencher valores ausentes (NaN) nos dados.

‚Ä¢	Modelos de Classifica√ß√£o:

o	from sklearn.ensemble import RandomForestClassifier: Importa o modelo Random Forest, um modelo robusto baseado em √°rvores de decis√£o.

o	from sklearn.svm import SVC: Importa o Support Vector Machine (SVM), outro modelo de classifica√ß√£o poderoso.

o	from sklearn.linear_model import LogisticRegression: Importa a Regress√£o Log√≠stica, um terceiro modelo (linear) que tamb√©m √© √≥timo para classifica√ß√£o.

‚Ä¢	M√©tricas de Avalia√ß√£o:

o	from sklearn.metrics import ...: Importa todas as fun√ß√µes necess√°rias para avaliar o desempenho dos modelos, conforme solicitado na atividade: accuracy_score (acur√°cia), precision_score (precis√£o), recall_score (recall), f1_score, roc_auc_score (curva ROC-AUC) e confusion_matrix (matriz de confus√£o).

‚Ä¢	Explicabilidade (XAI):

o	import shap: Importa a biblioteca SHAP. Esta √© uma ferramenta avan√ßada que ser√° usada para responder √† segunda pergunta da atividade: "Quais vari√°veis mais impactaram na previs√£o?".

‚Ä¢	Configura√ß√µes Adicionais:

o	sns.set_style(...): Define um estilo visual (whitegrid) para todos os gr√°ficos do Seaborn.

3. Carregamento dos Dados

‚Ä¢	df = pd.read_csv('heart_desease_data.csv'): Este comando usa o Pandas para ler o arquivo heart_desease_data.csv e o armazena na vari√°vel df (DataFrame), que √© a nossa tabela principal de trabalho.

<img width="886" height="493" alt="image" src="https://github.com/user-attachments/assets/af3b4d66-8179-4aa2-9654-1faa8a85508c" />

 
Este bloco de c√≥digo est√° preparando os dados para o modelo de machine learning.

1.	Ele primeiro separa o dataset em duas partes: as features (dados de entrada, como idade, colesterol) e o target (o que queremos prever: se tem ou n√£o doen√ßa).

2.	Em seguida, ele usa o StandardScaler para padronizar todas as features.

3.	Por que fazer isso? A padroniza√ß√£o coloca todas as vari√°veis na mesma escala (m√©dia 0, desvio padr√£o 1). Isso √© crucial para que modelos como o SVM funcionem corretamente e n√£o deem import√¢ncia indevida a vari√°veis que possuem n√∫meros grandes (como 'colesterol') em vez de vari√°veis com n√∫meros pequenos (como 'sex').

 <img width="886" height="388" alt="image" src="https://github.com/user-attachments/assets/03ef4bbd-5ad4-4a59-9831-02c4a7a874ea" />

Este bloco de c√≥digo define uma fun√ß√£o chamada plot_corr para visualizar a matriz de correla√ß√£o dos dados.

1.	corr = df_scaled.corr(): Este comando calcula a matriz de correla√ß√£o. Ela mostra um valor (entre -1 e 1) que mede a for√ßa da rela√ß√£o linear entre cada par de vari√°veis (por exemplo, como a "idade" se correlaciona com o "colesterol").

2.	ax.matshow(corr): Este comando usa o Matplotlib para desenhar um mapa de calor (heatmap) dessa matriz. As cores no gr√°fico representam os valores da correla√ß√£o (cores quentes para correla√ß√£o positiva, frias para negativa).

3.	plot_corr(df_scaled): Finalmente, o c√≥digo chama a fun√ß√£o para exibir esse mapa de calor.

Por que fazer isso? Para entender visualmente quais features (vari√°veis) est√£o fortemente conectadas umas com as outras, o que pode ser importante para a sele√ß√£o de features e para entender o comportamento do dataset.

<img width="886" height="528" alt="image" src="https://github.com/user-attachments/assets/b71832b9-0e13-4b69-9dbb-02c1e7841f40" />

Este bloco de c√≥digo realiza duas verifica√ß√µes cruciais da qualidade e integridade dos dados ap√≥s a padroniza√ß√£o:

1.	df_scaled.isnull().sum()

o	O que faz: Este comando verifica cada coluna do DataFrame df_scaled e conta quantos valores nulos (ausentes, NaN) existem em cada uma.

o	Por que fazer isso: Modelos de machine learning n√£o conseguem lidar com dados ausentes. A sa√≠da (que mostra 0 para todas as colunas) √© uma excelente not√≠cia, pois confirma que n√£o h√° valores nulos e que n√£o precisaremos de t√©cnicas de imputa√ß√£o (preenchimento de dados faltantes).

2.	df_scaled.describe()

o	O que faz: Este comando gera um resumo estat√≠stico detalhado para cada coluna num√©rica.

o	Por que fazer isso: Esta √© a prova final de que o StandardScaler (do bloco anterior) funcionou perfeitamente. Podemos observar na sa√≠da:

ÔÇß	mean (m√©dia): Todos os valores da m√©dia s√£o n√∫meros extremamente pequenos, muito pr√≥ximos de 0 (ex: 4.690515e-17, que √© 0.00...0469).

ÔÇß	std (desvio padr√£o): Todos os valores do desvio padr√£o s√£o exatamente 1.001654e+00 (que √© 1.001654, um valor muito pr√≥ximo de 1, a pequena diferen√ßa se deve ao c√°lculo amostral do pandas).

o	Isso confirma que todas as features est√£o agora na mesma escala padronizada, prontas para serem usadas pelos modelos.

<img width="886" height="566" alt="image" src="https://github.com/user-attachments/assets/94432f73-d26b-4710-ad29-28fa7c386a92" />

 
Este bloco de c√≥digo realiza duas tarefas principais: dividir os dados em conjuntos de treino/teste e treinar o primeiro modelo de classifica√ß√£o.

1.	Prepara√ß√£o dos Dados para sklearn:

o	data_treino = np.array(df_scaled): Converte o DataFrame df_scaled (as features padronizadas) em um array NumPy.

o	data_classif = np.array(target): Converte a s√©rie target (as respostas "0" ou "1") em um array NumPy.

o	Por qu√™? As bibliotecas do sklearn (como train_test_split e os modelos) s√£o otimizadas para trabalhar com arrays NumPy.

2.	Defini√ß√£o da Base de Treino e Teste:

o	x_treino, x_val, y_treino, y_val = train_test_split(...): Este comando divide os dados em quatro conjuntos:

ÔÇß	x_treino e y_treino: 70% dos dados, que ser√£o usados para treinar o modelo.

ÔÇß	x_val e y_val: 30% dos dados (definido por test_size=0.30), que ser√£o guardados para testar o modelo.

o	Por qu√™? Esta √© a etapa mais importante para uma avalia√ß√£o honesta. O modelo s√≥ pode "aprender" com os dados de treino. Os dados de teste (x_val, y_val) s√£o usados no final para ver o qu√£o bem o modelo generaliza para dados que ele nunca viu.

3.	Imprimindo os Resultados (Verifica√ß√£o):

o	Os comandos print(...) apenas calculam e mostram as porcentagens da divis√£o (69.97% treino, 30.03% teste), confirmando que a separa√ß√£o funcionou.

4.	Treinando o Modelo Random Forest:

o	rf = RandomForestClassifier(random_state=42): Inicializa o primeiro modelo, o RandomForestClassifier. O random_state=42 √© usado para garantir que os resultados sejam reproduz√≠veis.

o	rf.fit(x_treino, y_treino): Este √© o comando de treinamento. O modelo rf "aprende" os padr√µes nos dados de treino (x_treino) para prever as respostas (y_treino).

<img width="886" height="908" alt="image" src="https://github.com/user-attachments/assets/85af8f11-ab03-4985-841a-339dbab26e89" />

 
Este bloco de c√≥digo avalia o desempenho do modelo RandomForestClassifier que acabamos de treinar.

Ele faz duas avalia√ß√µes distintas:

1.	Avalia√ß√£o nos Dados de TREINO:

o	y_pred_treino = rf.predict(x_treino): O modelo faz previs√µes sobre os pr√≥prios dados que usou para treinar.

o	accuracy_score(y_treino, y_pred_treino): Compara as previs√µes com as respostas corretas.

o	Resultado (1.0): A acur√°cia foi de 100%. Isso indica que o modelo "decorou" perfeitamente os dados de treino, um sinal cl√°ssico de overfitting. O que importa de verdade √© o teste abaixo.

2.	Avalia√ß√£o nos Dados de TESTE (Valida√ß√£o):

o	y_pred_val = rf.predict(x_val): O modelo faz previs√µes sobre os dados de teste (x_val), que ele nunca viu antes. Este √© o teste real.

o	confusion_matrix(...): Gera a Matriz de Confus√£o.

ÔÇß	A sa√≠da [[41 9] [11 30]] significa (para as classes [1, 0]):

ÔÇß	41 Verdadeiros Positivos: Acertou 41 pacientes que tinham doen√ßa.

ÔÇß	9 Falsos Negativos: Errou 9 pacientes que tinham doen√ßa (disse que n√£o tinham).

ÔÇß	11 Falsos Positivos: Errou 11 pacientes que n√£o tinham doen√ßa (disse que tinham).

ÔÇß	30 Verdadeiros Negativos: Acertou 30 pacientes que n√£o tinham doen√ßa.

o	classification_report(...): Gera o relat√≥rio completo de m√©tricas.

ÔÇß	accuracy (Acur√°cia Total): 0.78 (O modelo acertou 78% de todas as previs√µes).

ÔÇß	precision (classe 1): 0.79 (Quando o modelo disse "tem doen√ßa", ele estava certo 79% das vezes).

ÔÇß	recall (classe 1): 0.82 (O modelo conseguiu identificar 82% de todos os pacientes que realmente tinham a doen√ßa).

<img width="600" height="827" alt="image" src="https://github.com/user-attachments/assets/69ec9de8-acd4-40e9-b1b4-6e4115d3f734" />

 
Este bloco de c√≥digo treina e avalia o segundo modelo da atividade, o Support Vector Machine (SVM), para que possamos compar√°-lo com o Random Forest.

1.	Treinando o Modelo SVM:

o	svm = SVC(random_state=42): Inicializa o modelo SVC (Support Vector Classifier).

o	svm.fit(x_treino, y_treino): Treina o modelo SVM usando os mesmos dados de treino (x_treino, y_treino) que o Random Forest usou.

2.	Avalia√ß√£o nos Dados de TREINO:

o	y_pred_treino = svm.predict(x_treino): O modelo faz previs√µes sobre os dados de treino.

o	accuracy_score(...): Calcula a acur√°cia.

o	Resultado (0.929...): A acur√°cia foi de 93%. Isso √© alto, mas (ao contr√°rio do Random Forest) n√£o √© 100%, o que sugere que o SVM est√° "decorando" menos os dados de treino e pode ter uma capacidade de generaliza√ß√£o melhor.

3.	Avalia√ß√£o nos Dados de TESTE (Valida√ß√£o):

o	y_pred_val = svm.predict(x_val): O modelo SVM faz previs√µes sobre os dados de teste (x_val).

o	confusion_matrix(...): Gera a Matriz de Confus√£o.

ÔÇß	A sa√≠da [[43 7] [14 27]] significa (para as classes [1, 0]):

ÔÇß	43 Verdadeiros Positivos: Acertou 43 pacientes que tinham doen√ßa.

ÔÇß	7 Falsos Negativos: Errou 7 pacientes que tinham doen√ßa (disse que n√£o tinham).

ÔÇß	14 Falsos Positivos: Errou 14 pacientes que n√£o tinham doen√ßa (disse que tinham).

ÔÇß	27 Verdadeiros Negativos: Acertou 27 pacientes que n√£o tinham doen√ßa.

o	classification_report(...): Gera o relat√≥rio de m√©tricas.

ÔÇß	accuracy (Acur√°cia Total): 0.77 (O modelo acertou 77% de todas as previs√µes).

ÔÇß	precision (classe 1): 0.75 (Quando o modelo disse "tem doen√ßa", ele estava certo 75% das vezes).

ÔÇß	recall (classe 1): 0.86 (O modelo conseguiu identificar 86% de todos os pacientes que realmente tinham a doen√ßa).

Compara√ß√£o r√°pida (SVM vs. RF): O SVM teve uma acur√°cia total ligeiramente menor (77% vs 78% do RF), mas alcan√ßou um Recall maior (86% vs 82%), o que significa que foi um pouco melhor em encontrar os pacientes que de fato estavam doentes.

<img width="886" height="498" alt="image" src="https://github.com/user-attachments/assets/1082899f-67ae-4790-a154-abeb000abba7" />

 
Este bloco de c√≥digo responde √† segunda pergunta da atividade: "Quais vari√°veis mais impactaram na previs√£o?", especificamente para o modelo Random Forest.

1.	importances = rf.feature_importances_:

o	O que faz: O modelo Random Forest (rf), ap√≥s ser treinado, armazena um "score" de import√¢ncia para cada feature (coluna) em um atributo chamado .feature_importances_. Esse score mede o quanto cada feature (idade, sexo, colesterol, etc.) contribuiu para tomar as decis√µes corretas.

2.	indices = np.argsort(importances)[::-1]:

o	O que faz: Este comando pega a lista de scores (importances) e a ordena, mas em vez de retornar os scores ordenados, ele retorna os √≠ndices (posi√ß√µes) das colunas, da mais importante para a menos importante.

ÔÇß	np.argsort() ordena do menor para o maior.

ÔÇß	[::-1] inverte a lista, para que o mais importante venha primeiro.

3.	print(indices):

o	O que faz: Imprime o ranking das features por import√¢ncia.

o	Sa√≠da: [ 2 7 9 0 11 12 4 3 10 8 1 6 5]

o	O que significa? Usando a tabela df_scaled como refer√™ncia (onde 'age' √© o √≠ndice 0, 'sex' √© o 1, 'cp' √© o 2, etc.), este ranking nos diz que:

ÔÇß	A feature mais importante √© a de √≠ndice 2 (cp - tipo de dor no peito).

ÔÇß	A segunda mais importante √© a de √≠ndice 7 (thalach - frequ√™ncia card√≠aca m√°xima).

ÔÇß	A terceira mais importante √© a de √≠ndice 9 (oldpeak).

ÔÇß	A quarta mais importante √© a de √≠ndice 0 (age).

e assim por diante.

<img width="886" height="652" alt="image" src="https://github.com/user-attachments/assets/056fac18-556d-425f-9119-9b7bce70f39e" />

 
Este bloco de c√≥digo instala uma nova biblioteca (eli5) para responder √† mesma pergunta ("Quais vari√°veis mais impactaram?"), mas desta vez para o modelo SVM.

O SVM n√£o possui um atributo .feature_importances_ simples como o Random Forest, por isso √© necess√°rio usar uma t√©cnica diferente chamada "Import√¢ncia por Permuta√ß√£o".

1.	%pip install eli5: Instala a biblioteca eli5, que √© especializada em "explicar" modelos de machine learning.

2.	from eli5.sklearn import PermutationImportance: Importa a ferramenta de "Import√¢ncia por Permuta√ß√£o".

3.	perm = PermutationImportance(svm, ...).fit(x_val, y_val): Este √© o comando principal.

o	O que faz: Ele usa o modelo svm treinado e os dados de teste (x_val, y_val).

o	Como funciona:

1.	Primeiro, ele mede a acur√°cia do SVM nos dados de teste (a "pontua√ß√£o base").

2.	Depois, ele pega uma coluna (ex: 'age'), embaralha os valores dela aleatoriamente e mede a acur√°cia de novo.

3.	Se a acur√°cia cair muito, significa que essa coluna era muito importante.

4.	Se a acur√°cia n√£o mudar (ou at√© melhorar um pouco), significa que a coluna era irrelevante ou prejudicial.

o	Ele repete esse processo para todas as colunas.

4.	eli5.show_weights(perm, feature_names=feature_names): Este comando exibe os resultados em uma tabela formatada.

O Resultado (A Tabela):

A tabela mostra o "Peso" (o quanto a acur√°cia do modelo caiu quando a feature foi embaralhada).

‚Ä¢	Para o SVM, a feature mais importante foi ca (n√∫mero de vasos principais).

‚Ä¢	A segunda foi thal.

‚Ä¢	A terceira foi cp (tipo de dor no peito).

‚Ä¢	Interessante notar que chol (colesterol) teve uma import√¢ncia negativa (-0.0223), o que sugere que essa feature pode ter mais confundido o SVM do que ajudado.



